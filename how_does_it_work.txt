1. postaw srodowisko
python -m venv .venv
source .venv/bin/activate        # Windows: .venv\Scripts\activate

2. zainstaluj co trzeba
pip install -r requirements.txt


--WAZNE
huggingface-cli login
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



3. pobieranie modelu bez trenowania
python app.py --model tiny

4. test jak dziala transkrypcja mowy z nagranego pliku
python transcribe_file.py sample.wav --model tiny --translate


5. pobranie danych 25gb
python data_prep.py \
  --dataset mozilla-foundation/common_voice_12_0 \
  --lang pl \
  --out data/cv_pl_clean

5. trenowanie okolo 90min
python train.py \
  --train_manifest data/cv_pl_clean/manifest_train.json.gz \
  --valid_manifest data/cv_pl_clean/manifest_valid.json.gz \
  --out_dir checkpoints/whisper-lora-pl


6. uruchamianie apki z wytrenowanym modelem
python app.py --model checkpoints/whisper-lora-pl


